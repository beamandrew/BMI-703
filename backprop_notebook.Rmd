---
title: "Backprop"
output: html_notebook
---
## Implementing a perceptron and backpropagation

In this notebook we are going to walk-through the nuts and bolts of training a simple perceptron with back propagation. First thing we need to do is load some data and some helper functions:
```{r}
source("https://raw.githubusercontent.com/beamandrew/BMI705/master/helper.R")
load(url("https://www.dropbox.com/s/unmfitketiba9i7/cat_dog_data_greyscale.RData?dl=1"))
options(repr.plot.width=4, repr.plot.height=4)
```
### Data Structure
The data we will be working with are images of cats and dogs, obtained from this kaggle [contest](https://www.kaggle.com/c/dogs-vs-cats) that have been resize to 64x64 images. For the moment, we will be working with black and white images to keep things simple. The `x_train` matrix is a with dimensions of `(2000,64,64)`. The first 1000 images are of cats and the second 1000 images are of dogs. Let's look at a few:
```{r}
display_image(x_train[2,,])
display_image(x_train[1002,,])
```

```{r}
## Flatten all of our images into row-vectors ##
x_train <- matrix(x_train,nrow=nrow(x_train))
x_test <- matrix(x_test,nrow=nrow(x_test))
print(paste0("Number of observations: " , nrow(x_train)))
print(paste0("Number of features: " , dim(x_train)[2], " by ", dim(x_train)[3]))

## Let's set up our weight vector with random values initially ##
w <- t(rnorm(ncol(x_train), mean = 0, sd=0.01))
```
This first thing we need to define is the _forward pass_. During the forward pass, the network computes the output probabilites for each input example. Given out input example $x_{i}$ and a weight vector $w$, we first compute the weighted sum for a single example (or logits if you're a stats person) like so:

$$h_{i} = \sum_{j=1}^{4096} x_{ij}*w_j$$

Next, we transfrom $h_i$ into a probability using the _sigmoid_ transformation:

$$\frac{1}{1+exp(-h_i)}$$
Below is a template of the forward pass, try to fill out the missing parts.The provided `sigmoid(h)` function is vectorized and will take the entire $h$ vector and apply the transform each element. 
```{r, eval=FALSE}
# This should return a vector representing the probability that y = 1 for each of the 2000 training samples
forward_pass <- function(X,w) {
    ## Compute the matrix-vector multiplication between the inputs and weights ##
    h <- 0 # Fill this in
    ## Transform into probabilities using the provided sigmoid() function ##
    probs <- 0 # Fill this in
    return(probs)
}
## See if it works ##
print("Dog probabilities for the first five samples:")
p <- forward_pass(x_train,w)
print(dim(p))
```
The next thing we need to do is to implement the _backward pass_. The backward pass computes the derivative of all our network's parameters with respect to the loss function. A typical loss function for binary classification is _log loss_ and for a single example is:

$$ \ell(y_i,p_i) = -y_i*log(p_i) - (1-y_i)*log(1-p_i) $$

The derivative of this function with respect to $w_j$ is:

$$ \frac{\partial w_j}{\partial \ell} = -(y_i - p_i)*x_{ij} $$

The full gradient is obtained by simply taking the average across all examples:

$$ \frac{\partial w_j}{\partial \ell} = \frac{1}{2000}\sum_{i=1}^{2000} -(y_i - p_i)*x_{ij} $$

Note we take the average instead of summing so that later our learning rate will be independent of the number of samples.
```{r}
## This function should return a vector the same size as the weight vector w. 
## Each element of the vector is the partial dervative evaluated at the current value of the loss function
backward_pass <- function(y, X, p) {
  grads <- 0 ## Fill this in
  return( grads )
}

## See if it works
grads <- backward_pass(y_train,x_train,p)
print(dim(grads))
```
Now it's time to run the gradient descent procedure. The update rule for each $w_j$ at each iteration is given by:

$$w_{j} =  w_{j} - \eta* \frac{\partial w_j}{\partial \ell} $$

where $\eta$ is the _learning rate_ and is typically some small number < 1. 

## In class assignment
Fill in the template below to train your perceptron. Try to see if you can get an accuracy ~ 65%. Note there will be some randomness in your loss and accruacy from run to run, even with the same parameters.
```{r}
## How many iterations to run gradient descent ##
epochs = 1000

## Initialize w ##
w <- t(rnorm(ncol(x_train), mean = 0, sd=0.01))

for(i in 1:epochs) {
  probs <- forward_pass(x_train,w)
  grads <- backward_pass(y_train, x_train, probs)
  ## Update the weights using the gradient descent rule ##
  w <- 0 # Fill the gradient descent update
  
  ## Print out some information every 100 epochs ##
  if(i %% 100 == 0) {
    message(paste0("\nReport at epoch: ", i))
    message(paste0("Loss: ", log_loss(y_train,probs)))
    message(paste0("Accuracy: ", binary_accuracy(y_train,probs)))
    message(paste0("Learning Rate: ", learning_rate))
  }
}
```



